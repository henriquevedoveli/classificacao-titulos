{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec_classificador.ipynb",
      "provenance": [],
      "mount_file_id": "1mR6U2n3465jTys2fOEngD85ukoAfQ8Z8",
      "authorship_tag": "ABX9TyNHyz4s/A82MkFBRuUN2w9O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/henriquevedoveli/classificacao-titulos/blob/master/word2vec_classificador.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N302kNIZHGqj",
        "colab_type": "text"
      },
      "source": [
        "# Classificando Títulos de Notícias Utilizando Word2Vec\n",
        "### ***Notebook de Classificação do Modelo***\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## ***Objetivo***\n",
        "#### Desenvolver um classificador capaz de realizar automaticamente o processo de categorização de títulos de notícias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLj0qhKDgtdD",
        "colab_type": "text"
      },
      "source": [
        "### Download do core em português (rodar apenas uma vez)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRrBdJC2-bZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "821fcf8f-e3f2-4e1d-df8c-13763448762f"
      },
      "source": [
        "# !python -m spacy download pt_core_news_sm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pt_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz (21.2MB)\n",
            "\u001b[K     |████████████████████████████████| 21.2MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (49.2.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: pt-core-news-sm\n",
            "  Building wheel for pt-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.2.5-cp36-none-any.whl size=21186282 sha256=272f9c8b707177c98d1ae97dd3715b32ae8954d347ebabc72f54fe879059f23e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6i13mhvs/wheels/ea/94/74/ec9be8418e9231b471be5dc7e1b45dd670019a376a6b5bc1c0\n",
            "Successfully built pt-core-news-sm\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zitZXDHdBm9",
        "colab_type": "text"
      },
      "source": [
        "Bibliotecas Necessárias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMXfpnpb_3Af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkBHX0aUevTK",
        "colab_type": "text"
      },
      "source": [
        "## Importando os Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yr3UOBO_gWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "65a79f4f-957f-475f-902a-e59150775fee"
      },
      "source": [
        "dados_treino = pd.read_csv('/content/drive/My Drive/data_science/classificacao-titulos/dados/treino.csv')\n",
        "dados_teste = pd.read_csv('/content/drive/My Drive/data_science/classificacao-titulos/dados/teste.csv')\n",
        "\n",
        "nlp = spacy.load('pt_core_news_sm', disable = ['paser', 'ner', 'tagger', 'textcat'])\n",
        "\n",
        "w2v_model_cbow = KeyedVectors.load_word2vec_format('/content/drive/My Drive/data_science/classificacao-titulos/model_cbow.txt')\n",
        "w2v_model_sg = KeyedVectors.load_word2vec_format('/content/drive/My Drive/data_science/classificacao-titulos/model_sg.txt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imcYXsYOey0C",
        "colab_type": "text"
      },
      "source": [
        "## Definindo uma função para tokenizar os textos\n",
        "\n",
        "#### A função recebe como parâmetro um texto ou um conjunto de texto e retorna os tokens válidos.\n",
        "####  A função transforma os textos em um doc, que é um objeto da biblioteca spacy. Dentro da função também ocorre um loop dentro dos textos que validam os tokens, os tokens válidos são aqueles que não são stop words e nem alfanúmericos, além disso caso os tokens sejam válidos as letras maiúsculas são transformadas em minúsculas.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jM37eryBlQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texto_para_teste = 'TEXTO para o teste das FUnções contendo palavras aleatorias 1235'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WimjcPwR_C-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizador(texto):\n",
        "  doc = nlp(texto)\n",
        "  tokens_validos = []\n",
        "  \n",
        "  for token in doc:\n",
        "    eh_valido = not token.is_stop and token.is_alpha\n",
        "    if eh_valido:\n",
        "      tokens_validos.append(token.text.lower())\n",
        "\n",
        "  return tokens_validos"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUlWub4AgzFW",
        "colab_type": "text"
      },
      "source": [
        "#### Rodadando a função para o texto de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMiWBlkGBuEs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e10551a-f53d-459d-fb61-4cd9e0a64ea2"
      },
      "source": [
        "tokens = tokenizador(texto_para_teste)\n",
        "print(tokens)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['texto', 'o', 'teste', 'funções', 'contendo', 'palavras', 'aleatorias']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRoHgtFdg5kw",
        "colab_type": "text"
      },
      "source": [
        "## Definindo uma função para ver o vetor resultante \n",
        "#### A função recebe como parâmetro os tokens válidos e o modelo a ser utilizado e retorna um vetor resultante de tamanho 300, com as distâncias das palavras.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-86B40lx--xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combinacao_por_soma(palavras, modelo):\n",
        "  vetor_r = np.zeros((1,300))\n",
        "\n",
        "  for token in palavras:\n",
        "    try:\n",
        "      vetor_r = vetor_r + modelo.get_vector(token)\n",
        "\n",
        "    except KeyError:\n",
        "      pass\n",
        "\n",
        "  return vetor_r"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHzUx7VMihkE",
        "colab_type": "text"
      },
      "source": [
        "#### Rodando o função para o texto de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzqE1hv7Be_C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ec0a3e7-56d7-433e-ffa9-4bb52ef369e3"
      },
      "source": [
        "vetor_texto = combinacao_por_soma(tokens, w2v_model_cbow)\n",
        "print(vetor_texto.shape)\n",
        "print(vetor_texto)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 300)\n",
            "[[ 2.58870368e+00  3.61491054e-01  2.88589448e-02 -5.97836580e-01\n",
            "   8.41937289e-02 -5.23671985e-01 -7.74942279e-01 -1.50745581e+00\n",
            "  -8.81823326e-01 -1.29006306e+00  2.09286910e-01  7.66616765e-01\n",
            "   1.40307825e-01 -1.14482539e+00  8.52251083e-01 -5.76672181e-02\n",
            "   4.11331765e-01 -4.79193963e-01 -4.68215356e-01 -1.20841229e+00\n",
            "  -2.03771736e+00  1.48951281e+00  1.33954011e+00 -5.30718867e-01\n",
            "  -7.38969356e-01 -4.79582500e-01 -3.92846901e-01 -1.84166358e-01\n",
            "  -1.54875653e+00 -1.22219776e+00 -9.96005945e-02  1.99837166e+00\n",
            "   2.06707408e+00 -9.20886017e-01 -2.35741479e+00 -8.78049500e-01\n",
            "  -3.15576077e-01 -5.37899429e-01  1.24734840e+00 -8.95041764e-01\n",
            "  -9.67134908e-01  9.33821984e-01 -5.91737241e-01  7.98646607e-01\n",
            "   1.14401853e+00  3.66217144e-01  1.03551268e+00 -1.05136736e+00\n",
            "   6.15798363e-01  6.62204638e-01 -1.11365431e+00  5.10009636e-01\n",
            "   3.19927744e-01 -9.21370678e-01  3.09843123e-01 -6.97124429e-01\n",
            "  -7.12333627e-01 -7.35972028e-01 -1.66838919e+00 -2.23825708e-01\n",
            "   2.45312587e-01 -5.10028811e-01 -2.66809637e-01  2.01041536e+00\n",
            "  -3.13939527e-05 -1.22058343e-01 -5.37238754e-01 -5.80079824e-01\n",
            "   1.11573147e+00 -3.34951637e-01 -1.13981374e+00  1.28711559e+00\n",
            "   5.03527317e-01 -2.18633667e-01 -9.67627689e-01 -5.09510916e-02\n",
            "   4.14689451e-01  2.00859219e-01 -9.08967912e-01 -4.05055881e-01\n",
            "  -7.06320748e-01 -4.83654231e-01  1.12655493e+00  3.79811227e-02\n",
            "  -9.19980258e-02  4.52779777e-01  1.28302735e+00  1.13031827e-02\n",
            "   2.45497337e-01 -2.70001433e+00 -6.38573475e-01 -1.53807305e-01\n",
            "   1.11561343e+00  6.66071631e-01 -1.79332525e+00 -1.06060427e+00\n",
            "   5.04223071e-02 -1.18075015e+00  2.80361023e-01  3.55241042e-01\n",
            "   9.64178495e-01  1.47974164e+00 -5.13846196e-01  2.48211811e+00\n",
            "  -4.25635749e-01 -1.44913685e+00 -1.38182759e+00 -2.36868021e+00\n",
            "   1.07751885e+00  3.59026704e-01  1.27828853e-01  7.65843362e-01\n",
            "  -1.22689705e+00  3.07194509e-01  1.35672861e+00  8.56849976e-01\n",
            "   8.48418251e-01 -2.08597905e+00 -2.50649517e+00 -8.78990941e-01\n",
            "  -9.03824959e-02  5.88659037e-01  1.30948177e+00 -1.21521403e+00\n",
            "  -7.71996537e-01  6.79109097e-02  5.09265676e-01  4.44055159e-01\n",
            "   1.16536345e+00  1.54812664e+00 -2.52687506e-01 -1.06818773e-01\n",
            "   5.57737601e-01  7.24857680e-01  2.05012599e+00 -6.48150647e-01\n",
            "  -1.34633263e+00 -2.14821316e-01  2.37380080e-01 -6.94558106e-01\n",
            "   2.25458942e-01  1.03287804e-01  6.59346424e-01  3.04862499e-01\n",
            "  -2.54933767e-01  7.28236649e-01  3.55188899e-01  8.85902298e-01\n",
            "   7.65491083e-01 -1.27294660e-02 -1.30138495e+00 -2.01202209e+00\n",
            "   9.65488331e-01  5.36281899e-01  9.46757283e-01  7.93976320e-01\n",
            "   1.76899383e+00  9.14175034e-01  1.23929494e+00  3.32160786e-01\n",
            "   5.13654709e-01  3.45301302e-01 -2.72692442e-02  1.33252567e+00\n",
            "   2.27926698e-01 -1.33589223e-01 -7.01826332e-01 -1.26095175e+00\n",
            "   2.14836104e+00 -6.09612040e-01  6.52881806e-01 -6.73870616e-01\n",
            "  -4.56845664e-01 -4.83321130e-01 -8.32568809e-01  8.57162669e-01\n",
            "  -1.54481784e-01 -8.07075929e-01 -6.52334765e-01 -5.66114679e-01\n",
            "  -8.39475214e-01  1.07364824e+00 -9.56373036e-01 -1.06276743e+00\n",
            "   5.95523193e-01 -6.79431200e-01 -2.22613916e+00 -5.79549000e-01\n",
            "  -1.38128568e+00 -3.05087786e-01  3.48716341e-01  6.73799142e-02\n",
            "   2.68299706e-01 -1.58201203e-01  4.46786612e-01  1.35355899e+00\n",
            "  -5.51939413e-01  1.26978776e+00 -3.74624409e-01  1.25459284e+00\n",
            "  -8.76663517e-01 -4.82648283e-01  3.48668346e-01  1.14245504e-01\n",
            "   3.12027946e-01  2.81073526e-01  5.85816652e-02 -1.45731435e+00\n",
            "   1.70058075e+00  9.68782231e-01 -4.20241982e-01  1.33827985e+00\n",
            "  -2.30884269e-01 -9.59722564e-01  1.97698109e+00 -1.84618399e-01\n",
            "  -9.08971921e-01 -2.42060164e+00  7.00476838e-01  1.10420024e+00\n",
            "   6.83858395e-01 -5.59433386e-01  2.22431394e+00  2.07924535e+00\n",
            "   5.76421394e-01  1.67540625e-01 -1.25633596e+00  7.59866353e-01\n",
            "  -8.65254779e-01  6.14714872e-01  1.70847139e+00 -6.76565453e-01\n",
            "   2.46962622e-01 -4.70974565e-01 -4.62432741e-01  1.25356188e+00\n",
            "  -1.00240967e+00 -4.45050566e-01 -1.80946777e+00  5.53314522e-01\n",
            "   1.93431601e-02  9.22453154e-01 -2.55871885e-01 -2.68815845e-01\n",
            "   9.69543476e-01 -4.92415331e-01  1.00321037e+00  1.10057590e+00\n",
            "  -2.36287579e-01 -9.11985792e-01  5.32489975e-01  1.28190009e+00\n",
            "   5.59286184e-01 -1.01199638e-01  9.52661476e-01  9.05423518e-01\n",
            "   4.34861612e-02 -4.39750375e-01 -9.71267149e-01  9.17171180e-01\n",
            "  -6.83075607e-01 -9.42503333e-01 -1.27376343e+00 -1.92220125e-01\n",
            "  -1.58920795e-01 -1.64451087e+00  9.12052164e-01  1.41033198e+00\n",
            "  -2.02134953e+00  4.39123437e-01 -7.63726898e-01  5.51754817e-01\n",
            "  -1.08594283e+00 -4.02824819e-01 -3.21767583e-01  3.60268846e-01\n",
            "  -1.06457800e-01 -2.27365156e+00  7.08267733e-01  4.85255603e-01\n",
            "   8.81868951e-01 -6.54435838e-01  1.70435670e+00  1.52163646e+00\n",
            "  -5.62001660e-01 -3.15763056e-01 -3.30077164e-01  8.63841191e-01\n",
            "   2.63238415e-01 -3.84701914e-01 -1.57711956e+00 -3.86896253e-01\n",
            "   9.93060425e-01  1.10876229e+00  1.05058431e+00  7.78424514e-01\n",
            "  -1.02373294e+00  6.78833231e-01  5.95635731e-01 -4.87720996e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGCzmkXfiqBw",
        "colab_type": "text"
      },
      "source": [
        "## Definindo uma função que retorna uma matriz com os vetores\n",
        "\n",
        "#### A função recebe como parâmetros os textos e o modelo a ser utilizado para o treinamento. A matriz terá o tamanho do tamanho do texto por 300, sendo os elementos as distâncias das palavras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGDoV3zt-qQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matriz_vetores(textos, modelo):\n",
        "  x = len(textos)\n",
        "  y = 300\n",
        "  matriz = np.zeros((x,y))\n",
        "\n",
        "  for i in range(x):  \n",
        "    palavras = tokenizador(textos.iloc[i])\n",
        "    matriz[i] = combinacao_por_soma(palavras, modelo)\n",
        "\n",
        "  return matriz "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lagQ33g4jrIx",
        "colab_type": "text"
      },
      "source": [
        "#### Construindo a matriz para o modelo CBOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnUWboUmCe6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6111a2be-000f-42ca-c196-755e9c103f6e"
      },
      "source": [
        "matriz_vetores_treino_cbow = matriz_vetores(dados_treino['title'], w2v_model_cbow)\n",
        "matriz_vetores_teste_cbow = matriz_vetores(dados_teste['title'], w2v_model_cbow)\n",
        "\n",
        "print(matriz_vetores_treino_cbow.shape)\n",
        "print(matriz_vetores_teste_cbow.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90000, 300)\n",
            "(20513, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuLBCc-Cjyep",
        "colab_type": "text"
      },
      "source": [
        "#### Construindo a matriz do modelo Skip-Gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkVL3u0ZdmYQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "560171fa-2c71-464b-a144-720cfaf4b244"
      },
      "source": [
        "matriz_vetores_treino_sg = matriz_vetores(dados_treino['title'], w2v_model_sg)\n",
        "matriz_vetores_teste_sg = matriz_vetores(dados_teste['title'], w2v_model_sg)\n",
        "\n",
        "print(matriz_vetores_treino_sg.shape)\n",
        "print(matriz_vetores_teste_sg.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90000, 300)\n",
            "(20513, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkJ1b7H2DkKN",
        "colab_type": "text"
      },
      "source": [
        "## Criando Modelo de Regressão Logística \n",
        "\n",
        "#### A função a seguir realiza o treino do Modelo de Regressão Logística recebendo como parâmetro o modelo (CBOW ou Skip-Gram) os dados de treino e os dados de teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX5inKLuDj0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classificador(modelo, x_treino, y_treino, x_teste, y_teste):\n",
        "  reg_log = LogisticRegression(max_iter = 800)\n",
        "  reg_log.fit(x_treino, y_treino)\n",
        "  categorias = reg_log.predict(x_teste)\n",
        "  results = classification_report(y_teste, categorias)\n",
        "\n",
        "  print(results)\n",
        "\n",
        "  return reg_log"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcdsyysdDSf8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "26b8892b-2d06-468d-a378-ad70208926cd"
      },
      "source": [
        "reg_log_cbow = classificador(w2v_model_cbow, \n",
        "                        matriz_vetores_treino_cbow, dados_treino['category'],\n",
        "                        matriz_vetores_teste_cbow, dados_teste['category'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     colunas       0.81      0.71      0.76      6103\n",
            "   cotidiano       0.64      0.80      0.71      1698\n",
            "     esporte       0.93      0.87      0.90      4663\n",
            "   ilustrada       0.12      0.82      0.22       131\n",
            "     mercado       0.84      0.78      0.81      5867\n",
            "       mundo       0.74      0.83      0.78      2051\n",
            "\n",
            "    accuracy                           0.79     20513\n",
            "   macro avg       0.68      0.80      0.69     20513\n",
            "weighted avg       0.82      0.79      0.80     20513\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOrHpdzNvYjb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "7e33aa1e-d784-449d-d6b4-ebf01c577629"
      },
      "source": [
        "reg_log_sg = classificador(w2v_model_sg, \n",
        "                        matriz_vetores_treino_sg, dados_treino['category'],\n",
        "                        matriz_vetores_teste_sg, dados_teste['category'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     colunas       0.81      0.72      0.76      6103\n",
            "   cotidiano       0.65      0.80      0.72      1698\n",
            "     esporte       0.93      0.88      0.91      4663\n",
            "   ilustrada       0.14      0.86      0.24       131\n",
            "     mercado       0.84      0.79      0.81      5867\n",
            "       mundo       0.75      0.84      0.79      2051\n",
            "\n",
            "    accuracy                           0.79     20513\n",
            "   macro avg       0.69      0.82      0.71     20513\n",
            "weighted avg       0.82      0.79      0.80     20513\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkTIUSUoeGdB",
        "colab_type": "text"
      },
      "source": [
        "## Salvando os Modelos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka9kQHN0E3n6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/data_science/classificacao-titulos/rl_cbow.sav','wb') as f:\n",
        "  pickle.dump(reg_log_cbow, f)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQRFxeaXHMUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/data_science/classificacao-titulos/rl_sg.sav','wb') as f:\n",
        "  pickle.dump(reg_log_sg, f)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnu2YewOktyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}